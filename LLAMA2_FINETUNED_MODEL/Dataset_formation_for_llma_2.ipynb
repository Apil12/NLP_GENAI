{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVCyM3as3Wmq"
      },
      "outputs": [],
      "source": [
        "\n",
        "import transformers\n",
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "with open(\"/content/qna deep dataset.txt\", 'r') as file:\n",
        "\n",
        "    file_contents = file.readlines()\n",
        "\n",
        "ques=[]\n",
        "ans=[]\n",
        "for line in file_contents:\n",
        "   if line !=\"\\n\":\n",
        "      if line.split()[0]==\"Question:\":\n",
        "          ques.append(line.replace(\"\\n\",\"\"))\n",
        "      else:\n",
        "          ans.append(line.replace(\"\\n\",\"\"))\n",
        "\n",
        "# remove Question: ques\n",
        "f_que=[]\n",
        "for i in ques:\n",
        "  f_que.append(i.replace(\"Question:\",\"\"))\n",
        "\n",
        "# remove Question: ques\n",
        "f_ans=[]\n",
        "for i in ans:\n",
        "  f_ans.append(i.replace(\"Answer:\",\"\"))"
      ],
      "metadata": {
        "id": "6DXybI4v3alR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id=\"meta-llama/Llama-2-7b-hf\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "final_chat = []\n",
        "\n",
        "for i in range(len(f_que)):\n",
        "    que = {\"role\": \"user\", \"content\": f_que[i]}\n",
        "    ans = {\"role\": \"assistant\", \"content\": f_ans[i]}\n",
        "    final_chat.append(que)\n",
        "    final_chat.append(ans)\n",
        "\n",
        "chat_to_format=tokenizer.apply_chat_template(final_chat, tokenize=False)\n",
        "\n",
        "slitted=chat_to_format.split(\"\")\n",
        "\n",
        "final_out=[i.strip()+\"\" for i in slitted if i!=\"\"]\n",
        "\n",
        "df=pd.DataFrame(final_out)\n",
        "\n",
        "df.head(10)\n"
      ],
      "metadata": {
        "id": "m0TSP-6N3eyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('apilfile.csv', index=False)"
      ],
      "metadata": {
        "id": "CTSbp7eV3jEz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}